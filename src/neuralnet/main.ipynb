{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from Layer import *\n",
    "from network import Network\n",
    "from activation_func import tanh, tanh_prime, sigmoid, sigmoid_prime, softmax, softmax_prime, relu, relu_prime\n",
    "from loss_func import mse, mse_prime, cross_entropy, cross_entropy_prime\n",
    "from data_func import vectorize_labels, k_fold\n",
    "from confusion_matrix import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "dataset = np.load(\"../dataset.npz\")\n",
    "training = dataset['arr_0'][:6000]  # training_img\n",
    "labels = vectorize_labels(dataset['arr_2'][:6000])  # training_labels\n",
    "test = dataset['arr_1']  # test_img\n",
    "original_test_labels = dataset['arr_3']  # test_labels\n",
    "test_labels = vectorize_labels(original_test_labels)\n",
    "np.random.seed(10)\n",
    "\n",
    "# normalize data\n",
    "training /= 255\n",
    "test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 5e-3\n",
    "hidden_layers = [300, 200, 100]\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "weight_decay = 0.01\n",
    "\n",
    "# functions\n",
    "activation = relu\n",
    "activation_prime = relu_prime\n",
    "loss = cross_entropy\n",
    "loss_prime = cross_entropy_prime\n",
    "loss_activation = softmax\n",
    "loss_activation_prime = softmax_prime\n",
    "\n",
    "# test size\n",
    "test_size = 10000\n",
    "\n",
    "# specify input and output parameters\n",
    "features = 784\n",
    "output_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10   training error=4.617074  validation error=0.935300 validation accuracy=0.726667\n",
      "epoch 2/10   training error=0.624157  validation error=0.647859 validation accuracy=0.825000\n",
      "epoch 3/10   training error=0.398579  validation error=0.578385 validation accuracy=0.834167\n",
      "epoch 4/10   training error=0.282573  validation error=0.499965 validation accuracy=0.865000\n",
      "epoch 5/10   training error=0.212001  validation error=0.480768 validation accuracy=0.880000\n",
      "epoch 6/10   training error=0.166453  validation error=0.421059 validation accuracy=0.892500\n",
      "epoch 7/10   training error=0.128018  validation error=0.437889 validation accuracy=0.898333\n",
      "epoch 8/10   training error=0.097608  validation error=0.435638 validation accuracy=0.894167\n",
      "epoch 9/10   training error=0.073666  validation error=0.438201 validation accuracy=0.903333\n",
      "epoch 10/10   training error=0.062203  validation error=0.430668 validation accuracy=0.906667\n",
      "The test accuracy of the network is: 0.8864\n"
     ]
    }
   ],
   "source": [
    "# set up the network with specified layers, loss, and activation\n",
    "net = Network()\n",
    "net.setup_net(hidden_layers, activation, features, output_classes,\n",
    "              activation_prime,\n",
    "              loss_activation, loss_activation_prime,\n",
    "              loss, loss_prime,\n",
    "              FCLayer, ActivationLayer, LossLayer)\n",
    "\n",
    "# prepare data for training\n",
    "fold_train_data, fold_train_labels, fold_val_data, fold_val_labels = k_fold(training, labels, 5, 5)\n",
    "\n",
    "# train the model on training data and labels using specific hyper-parameters\n",
    "errors, val_errors = net.fit(fold_train_data, fold_train_labels, fold_val_data, fold_val_labels,\n",
    "                             epochs=epochs, learning_rate=learning_rate, batch_size=batch_size, momentum=True, weight_decay=weight_decay)\n",
    "\n",
    "# print the accuracy\n",
    "print(\"The test accuracy of the network is: {}\"\n",
    "      .format(\n",
    "    net.accuracy(x=test[:test_size], y_true=original_test_labels[:test_size], errors=errors, val_errors=val_errors)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error(error, val_error):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(error, 'r', label=\"training loss ({:.6f})\".format(error[-1]))\n",
    "    ax1.plot(val_error, 'b--', label=\"validation loss ({:.6f})\".format(val_error[-1]))\n",
    "    ax1.grid(True)\n",
    "    ax1.set_xlabel('iteration')\n",
    "    ax1.legend(loc=\"best\", fontsize=9)\n",
    "    ax1.set_ylabel('loss', color='r')\n",
    "    ax1.tick_params('y', colors='r')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_error(errors, val_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
